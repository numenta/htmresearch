{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP 1-Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nupic.bindings.algorithms import TemporalMemory as TM\n",
    "from htmresearch.support.neural_correlations_utils import *\n",
    "    \n",
    "uintType = \"uint32\"\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbolsPerSequence = 10\n",
    "numSequences = 1000\n",
    "epochs = 20\n",
    "totalTS = epochs * numSequences * symbolsPerSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tm = TM(columnDimensions = (2048,),\n",
    "    cellsPerColumn=8,\n",
    "    initialPermanence=0.21,\n",
    "    connectedPermanence=0.3,\n",
    "    minThreshold=15,\n",
    "    maxNewSynapseCount=40,\n",
    "    permanenceIncrement=0.1,\n",
    "    permanenceDecrement=0.1,\n",
    "    activationThreshold=15,\n",
    "    predictedSegmentDecrement=0.01,\n",
    "    )\n",
    "\n",
    "sparsity = 0.02\n",
    "sparseCols = int(tm.numberOfColumns() * sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed sequences to the TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "allSequences = []\n",
    "for s in range(numSequences):\n",
    "    sequence = generateRandomSequence(symbolsPerSequence, tm.numberOfColumns(), sparsity)\n",
    "    allSequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikeTrains = np.zeros((tm.numberOfCells(), totalTS), dtype = \"uint32\")\n",
    "columnUsage = np.zeros(tm.numberOfColumns(), dtype=\"uint32\")\n",
    "spikeCount = np.zeros(totalTS, dtype=\"uint32\")\n",
    "ts = 0\n",
    "\n",
    "entropyX = []\n",
    "entropyY = []\n",
    "\n",
    "negPCCX_cells = []\n",
    "negPCCY_cells = []\n",
    "\n",
    "numSpikesX = []\n",
    "numSpikesY = []\n",
    "\n",
    "numSpikes = 0\n",
    "\n",
    "negPCCX_cols = []\n",
    "negPCCY_cols = []\n",
    "\n",
    "# Randomly generate the indices of the columns to keep track during simulation time\n",
    "colIndicesLarge = np.random.permutation(tm.numberOfColumns())[0:125] # keep track of 125 columns = 1000 cells\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # shuffle sequences\n",
    "    print \"\"\n",
    "    print \"Epoch: \" + str(epoch)\n",
    "    seqIndices = np.random.permutation(np.arange(numSequences))\n",
    "    \n",
    "    for s in range(numSequences):\n",
    "        if s > 0 and s % 100 == 0:\n",
    "            print str(s) + \" sequences processed\"\n",
    "        for symbol in range(symbolsPerSequence):\n",
    "            tm.compute(allSequences[seqIndices[s]][symbol], learn=True)\n",
    "            \n",
    "            for cell in tm.getActiveCells():\n",
    "                spikeTrains[cell, ts] = 1\n",
    "                numSpikes += 1\n",
    "                spikeCount[ts] += 1\n",
    "                \n",
    "            # Obtain active columns:\n",
    "            activeColumnsIndices = [tm.columnForCell(i) for i in tm.getActiveCells()]\n",
    "            currentColumns = [1 if i in activeColumnsIndices else 0 for i in range(tm.numberOfColumns())]\n",
    "            for col in np.nonzero(currentColumns)[0]:\n",
    "                columnUsage[col] += 1\n",
    "                \n",
    "            if ts > 0 and ts % int(totalTS * 0.1) == 0:\n",
    "                numSpikesX.append(ts)\n",
    "                numSpikesY.append(numSpikes)            \n",
    "                numSpikes = 0\n",
    "                \n",
    "                #print \"++ Analyzing correlations (cells at random) ++\"                \n",
    "                subSpikeTrains = subSample(spikeTrains, 1000, tm.numberOfCells(), ts)\n",
    "                (corrMatrix, numNegPCC) = computePWCorrelations(subSpikeTrains, removeAutoCorr=True)\n",
    "                negPCCX_cells.append(ts)\n",
    "                negPCCY_cells.append(numNegPCC)                \n",
    "                bins = 300\n",
    "                plt.hist(corrMatrix.ravel(), bins, alpha=0.5)                \n",
    "                # Set range for plot appropriately!\n",
    "                plt.xlim(-0.05,0.1)\n",
    "                plt.xlabel(\"PCC\")\n",
    "                plt.ylabel(\"Frequency\")\n",
    "                plt.savefig(\"cellsHist_\" + str(ts))\n",
    "                plt.close()\n",
    "                entropyX.append(ts)\n",
    "                entropyY.append(computeEntropy(subSpikeTrains))                \n",
    "\n",
    "                #print \"++ Analyzing correlations (whole columns) ++\"\n",
    "                ### First the LARGE subsample of columns:\n",
    "                subSpikeTrains = subSampleWholeColumn(spikeTrains, colIndicesLarge, tm.getCellsPerColumn(), ts)\n",
    "                (corrMatrix, numNegPCC) = computePWCorrelations(subSpikeTrains, removeAutoCorr=True)\n",
    "                negPCCX_cols.append(s)\n",
    "                negPCCY_cols.append(numNegPCC)                \n",
    "                #print \"++ Generating histogram ++\"\n",
    "                bins = 300\n",
    "                plt.hist(corrMatrix.ravel(), bins, alpha=0.5)\n",
    "                plt.xlim(-0.05,0.1)\n",
    "                plt.xlabel(\"PCC\")\n",
    "                plt.ylabel(\"Frequency\")\n",
    "                plt.savefig(\"colsHist_\" + str(ts))\n",
    "                plt.close()                 \n",
    "                \n",
    "            ts += 1\n",
    "            \n",
    "print \"*** DONE ***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsityTraceX = []\n",
    "sparsityTraceY = []\n",
    "for i in range(totalTS - 1000):\n",
    "    sparsityTraceX.append(i)\n",
    "    sparsityTraceY.append(np.mean(spikeCount[i:1000 + i]) / tm.numberOfCells())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(sparsityTraceX, sparsityTraceY)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Sparsity\")\n",
    "plt.savefig(\"sparsityTrace\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot trace of negative PCCs\n",
    "plt.plot(negPCCX_cells, negPCCY_cells)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Negative PCC Count\")\n",
    "plt.savefig(\"negPCCTrace_cells\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(negPCCX_cols, negPCCY_cols)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Negative PCC Count\")\n",
    "plt.savefig(\"negPCCTrace_cols\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(numSpikesX, numSpikesY)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Num Spikes\")\n",
    "plt.savefig(\"numSpikesTrace\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot entropy\n",
    "plt.plot(entropyX, entropyY)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.savefig(\"entropyTM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(columnUsage)\n",
    "plt.xlabel(\"Number of times active\")\n",
    "plt.ylabel(\"Number of columns\")\n",
    "plt.savefig(\"columnUsage\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISI analysis (with Poisson model too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subSpikeTrains = subSample(spikeTrains, 1000, tm.numberOfCells(), totalTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isi = computeISI(subSpikeTrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print ISI distribution of TM\n",
    "\n",
    "#bins = np.linspace(np.min(isi), np.max(isi), 50)\n",
    "bins = 100\n",
    "plt.hist(isi, bins)\n",
    "plt.xlim(0,1000)\n",
    "# plt.xlim(89500,92000)\n",
    "plt.xlabel(\"ISI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"isiTM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(isi)\n",
    "print np.std(isi)\n",
    "print np.std(isi)/np.mean(isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate spike distribution\n",
    "spikeCount = []\n",
    "for cell in range(np.shape(subSpikeTrains)[0]):\n",
    "    spikeCount.append(np.count_nonzero(subSpikeTrains[cell,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = 25\n",
    "plt.hist(spikeCount, bins)\n",
    "plt.xlabel(\"Spike Count\")\n",
    "plt.ylabel(\"Number of cells\")\n",
    "plt.savefig(\"spikesHist_TM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firingRate = 18\n",
    "pSpikeTrain = poissonSpikeGenerator(firingRate,np.shape(subSpikeTrains)[1],np.shape(subSpikeTrains)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isi = computeISI(pSpikeTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print ISI distribution of Poisson model\n",
    "\n",
    "#bins = np.linspace(np.min(isi), np.max(isi), 50)\n",
    "bins = 100\n",
    "plt.hist(isi, bins)\n",
    "plt.xlim(0,600)\n",
    "# plt.xlim(89500,92000)\n",
    "plt.xlabel(\"ISI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"isiPOI\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(isi)\n",
    "print np.std(isi)\n",
    "print np.std(isi)/np.mean(isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate spike distribution\n",
    "spikeCount = []\n",
    "for cell in range(np.shape(pSpikeTrain)[0]):\n",
    "    spikeCount.append(np.count_nonzero(pSpikeTrain[cell,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = 25\n",
    "plt.hist(spikeCount, bins)\n",
    "plt.xlabel(\"Spike Count\")\n",
    "plt.ylabel(\"Number of cells\")\n",
    "plt.savefig(\"spikesHist_POI\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subSpikeTrains = subSample(spikeTrains, 100, tm.numberOfCells(), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rasterPlot(subSpikeTrains, \"TM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pSpikeTrain = poissonSpikeGenerator(firingRate,np.shape(subSpikeTrains)[1],np.shape(subSpikeTrains)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rasterPlot(pSpikeTrain, \"Poisson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Accuracy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simpleAccuracyTest(\"random\", tm, allSequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elad Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample from both TM_SpikeTrains and Poisson_SpikeTrains. 10 cells for 1000 (?) timesteps\n",
    "wordLength = 10\n",
    "firingRate = 18 \n",
    "\n",
    "# generate all 2^N strings:\n",
    "binaryStrings = list(itertools.product([0, 1], repeat=wordLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trials = 100\n",
    "\n",
    "x = [] #observed\n",
    "y = [] #predicted by random model\n",
    "\n",
    "for t in range(trials):\n",
    "    print \"Trial: \" + str(t)\n",
    "    # sample from spike trains\n",
    "    subSpikeTrains = subSample(spikeTrains, wordLength, tm.numberOfCells(), totalTS)\n",
    "    pSpikeTrain = poissonSpikeGenerator(firingRate,np.shape(subSpikeTrains)[1],np.shape(subSpikeTrains)[0])    \n",
    "    for i in range(2**wordLength):\n",
    "        if i == 0:\n",
    "            continue\n",
    "#         if i % 100 == 0:\n",
    "#             print str(i) + \" words processed\"\n",
    "        binaryWord = np.array(binaryStrings[i], dtype=\"uint32\")\n",
    "        x.append(countInSample(binaryWord, subSpikeTrains))\n",
    "        y.append(countInSample(binaryWord, pSpikeTrain))\n",
    "#     print \"**All words processed**\"    \n",
    "#     print \"\"\n",
    "print \"*** DONE ***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(x, y, 'bo',basex=10)\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.plot(x,x,'k-')\n",
    "plt.xlim(0,np.max(x))\n",
    "plt.savefig(\"EladPlot\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveTM(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to load the TM back from the file do:\n",
    "with open('tm.nta', 'rb') as f:\n",
    "    proto2 = TemporalMemoryProto_capnp.TemporalMemoryProto.read(f, traversal_limit_in_words=2**61)\n",
    "tm = TM.read(proto2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlapMatrix = inputAnalysis(allSequences, \"random\", tm.numberOfColumns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show heatmap of overlap matrix\n",
    "plt.imshow(overlapMatrix, cmap='spectral', interpolation='nearest')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Overlap Score')\n",
    "plt.savefig(\"overlapScore_heatmap\")\n",
    "plt.close()\n",
    "# plt.show()\n",
    "\n",
    "# generate histogram\n",
    "bins = 60\n",
    "(n, bins, patches) = plt.hist(overlapMatrix.ravel(), bins, alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Overlap Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"overlapScore_hist\")\n",
    "\n",
    "plt.xlim(0,0.15)\n",
    "plt.xlabel(\"Overlap Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"overlapScore_hist_ZOOM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "trials = 1000\n",
    "for t in range(trials):\n",
    "    pSpikeTrain = poissonSpikeGenerator(18,1000,1)\n",
    "    x.append(np.count_nonzero(pSpikeTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = 25\n",
    "plt.hist(x, bins)\n",
    "plt.savefig(\"test_spikePOI\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
