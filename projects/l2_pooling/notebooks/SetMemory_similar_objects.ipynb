{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, some code. Scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy\n",
    "\n",
    "from nupic.bindings.math import SparseBinaryMatrix, GetNTAReal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functionality that could be implemented in SparseBinaryMatrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeSparseBinaryMatrix(numRows, numCols):\n",
    "    \"\"\"\n",
    "    Construct a SparseBinaryMatrix.\n",
    "\n",
    "    There is a C++ constructor that does this, but it's currently not available\n",
    "    to Python callers.\n",
    "    \"\"\"\n",
    "    matrix = SparseBinaryMatrix(numCols)\n",
    "    matrix.resize(numRows, numCols)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def rightVecSumAtNZ_sparse(sparseMatrix, sparseBinaryArray):\n",
    "    \"\"\"\n",
    "    Like rightVecSumAtNZ, but it supports sparse binary arrays.\n",
    "\n",
    "    @param sparseBinaryArray (sequence)\n",
    "    A sorted list of indices.\n",
    "\n",
    "    Note: this Python implementation doesn't require the list to be sorted, but\n",
    "    an eventual C implementation would.\n",
    "    \"\"\"\n",
    "    denseArray = numpy.zeros(sparseMatrix.nCols(), dtype=GetNTAReal())\n",
    "    denseArray[sparseBinaryArray] = 1\n",
    "    return sparseMatrix.rightVecSumAtNZ(denseArray)\n",
    "\n",
    "\n",
    "def setOuterToOne(sparseMatrix, rows, cols):\n",
    "    \"\"\"\n",
    "    Equivalent to:\n",
    "\n",
    "    SparseMatrix.setOuter(rows, cols,\n",
    "                          numpy.ones((len(rows),len(cols)))\n",
    "\n",
    "    But it works with the SparseBinaryMatrix. If this functionality is added to\n",
    "    the SparseBinaryMatrix, it will have the added benefit of not having to\n",
    "    construct a big array of ones.\n",
    "    \"\"\"\n",
    "    for rowNumber in rows:\n",
    "        sparseRow = sorted(set(sparseMatrix.getRowSparse(rowNumber)).union(cols))\n",
    "        sparseMatrix.replaceSparseRow(rowNumber, sparseRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This SetMemory docstring is worth reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SetMemory(object):\n",
    "    \"\"\"\n",
    "    Uses proximal synapses, distal dendrites, and inhibition to implement \"set\n",
    "    memory\" with neurons. Set Memory can recognize a set via a series of\n",
    "    inputs. It associates an SDR with each set, growing proximal synapses from\n",
    "    each cell in the SDR to each proximal input. When the SetMemory receives an\n",
    "    ambiguous input, it activates a union of these SDRs. As it receives other\n",
    "    inputs, each SDR stays active only if it has both feedforward and lateral\n",
    "    support. Each SDR has lateral connections to itself, so an SDR has lateral\n",
    "    support if it was active in the previous time step. Over time, the union is\n",
    "    narrowed down to a single SDR.\n",
    "\n",
    "    Requiring feedforward and lateral support is functionally similar to computing\n",
    "    the intersection of the feedforward support and the previous active cells.\n",
    "    The advantages of this approach are:\n",
    "\n",
    "    1. Better noise robustness. If cell is randomly inactive, it's not excluded in\n",
    "       the next time step.\n",
    "    2. It doesn't require any new neural phenomena. It accomplishes all this\n",
    "       through distal dendrites and inhibition.\n",
    "    3. It combines well with other parallel layers. A cell can grow one distal\n",
    "       dendrite segment for each layer and connect each to an object SDR, and use\n",
    "       the number of active dendrite segments to drive inhibition.\n",
    "\n",
    "    This doesn't model:\n",
    "\n",
    "    - Synapse permanences. When it grows a synapse, it's immediately connected.\n",
    "    - Subsampling. When growing synapses to active cells, it simply grows\n",
    "      synapses to every one.\n",
    "\n",
    "    These aren't needed for this experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 layerID,\n",
    "                 feedforwardID,\n",
    "                 lateralIDs,\n",
    "                 layerSizes,\n",
    "                 sdrSize,\n",
    "                 minThresholdProximal,\n",
    "                 minThresholdDistal):\n",
    "        \"\"\"\n",
    "        @param layerID\n",
    "        The layer whose activity this SetMemory should update.\n",
    "\n",
    "        @param feedforwardID\n",
    "        The layer that this layer might form feedforward connections to.\n",
    "\n",
    "        @param lateralIDs (iter)\n",
    "        The layers that this layer might form lateral connections to.\n",
    "        If this layer will form internal lateral connections, this list must include\n",
    "        this layer's layerID.\n",
    "\n",
    "        @param layerSizes (dict)\n",
    "        A dictionary from layerID to number of cells. It must contain a size for\n",
    "        layerID, feedforwardID, and each of the lateralIDs.\n",
    "\n",
    "        @param sdrSize (int)\n",
    "        The number of cells in an SDR.\n",
    "\n",
    "        @param minThresholdProximal (int)\n",
    "        The number of active feedforward synapses required for a cell to have\n",
    "        \"feedforward support\".\n",
    "\n",
    "        @param minThresholdDistal (int)\n",
    "        The number of active distal synapses required for a segment to be active.\n",
    "        \"\"\"\n",
    "        self.layerID = layerID\n",
    "        self.feedforwardID = feedforwardID\n",
    "        self.sdrSize = sdrSize\n",
    "        self.minThresholdProximal = minThresholdProximal\n",
    "        self.minThresholdDistal = minThresholdDistal\n",
    "\n",
    "        # Matrix of connected synapses. Permanences aren't modelled.\n",
    "        self.proximalConnections = makeSparseBinaryMatrix(layerSizes[layerID],\n",
    "                                                          layerSizes[feedforwardID])\n",
    "\n",
    "        # Synapses to lateral layers. Each matrix represents one segment per cell.\n",
    "        # A cell won't grow more than one segment to another layer. If the cell\n",
    "        # appears in multiple object SDRs, it will connect its segments to a union\n",
    "        # of object SDRs.\n",
    "        self.lateralConnections = dict(\n",
    "            (lateralID, makeSparseBinaryMatrix(layerSizes[layerID],\n",
    "                                               layerSizes[lateralID]))\n",
    "            for lateralID in lateralIDs)\n",
    "\n",
    "        self.numCells = layerSizes[layerID]\n",
    "\n",
    "        self.isReset = True\n",
    "\n",
    "\n",
    "    def learningCompute(self, activity):\n",
    "        \"\"\"\n",
    "        Chooses active cells using the previous active cells and the reset signal.\n",
    "        Grows proximal synapses to the feedforward layer's current active cells, and\n",
    "        grows lateral synapses to the each lateral layer's previous active cells.\n",
    "\n",
    "        Reads:\n",
    "\n",
    "        - activity[0][feedforwardID][\"activeCells\"]\n",
    "        - activity[1][lateralID][\"activeCells\"] for each lateralID\n",
    "\n",
    "        Writes to:\n",
    "\n",
    "        - activity[0][layerID][\"activeCells\"]\n",
    "        - The feedforward connections matrix\n",
    "        - The lateral connections matrices\n",
    "        \"\"\"\n",
    "\n",
    "        # Select active cells\n",
    "        if self.isReset:\n",
    "            activeCells = sorted(random.sample(xrange(self.numCells), self.sdrSize))\n",
    "            self.isReset = False\n",
    "        else:\n",
    "            activeCells = activity[1][self.layerID][\"activeCells\"]\n",
    "\n",
    "            # Lateral learning\n",
    "            if len(activity) > 1:\n",
    "                for lateralID, connections in self.lateralConnections.iteritems():\n",
    "                    setOuterToOne(connections, activeCells,\n",
    "                                  activity[1][lateralID][\"activeCells\"])\n",
    "\n",
    "        # Proximal learning\n",
    "        setOuterToOne(self.proximalConnections, activeCells,\n",
    "                      activity[0][self.feedforwardID][\"activeCells\"])\n",
    "\n",
    "        # Write the activity\n",
    "        activity[0][self.layerID][\"activeCells\"] = activeCells\n",
    "\n",
    "\n",
    "    def inferenceCompute(self, activity):\n",
    "        \"\"\"\n",
    "        Chooses active cells using feedforward and lateral input.\n",
    "\n",
    "        Reads:\n",
    "\n",
    "        - activity[0][feedforwardID][\"activeCells\"]\n",
    "        - activity[1][lateralID][\"activeCells\"] for each lateralID\n",
    "\n",
    "        Writes to:\n",
    "\n",
    "        - activity[0][layerID][\"activeCells\"]\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate feedforward support\n",
    "        overlaps = rightVecSumAtNZ_sparse(self.proximalConnections,\n",
    "                                          activity[0][self.feedforwardID][\"activeCells\"])\n",
    "        feedforwardSupportedCells = set(\n",
    "            numpy.where(overlaps >= self.minThresholdProximal)[0])\n",
    "\n",
    "        # Calculate lateral support\n",
    "        numActiveSegmentsByCell = numpy.zeros(self.numCells)\n",
    "        if self.isReset:\n",
    "            # Don't activate any segments\n",
    "            self.isReset = False\n",
    "        elif len(activity) >= 2:\n",
    "            for lateralID, connections in self.lateralConnections.iteritems():\n",
    "                overlaps = rightVecSumAtNZ_sparse(connections,\n",
    "                                                  activity[1][lateralID][\"activeCells\"])\n",
    "                numActiveSegmentsByCell[overlaps >= self.minThresholdDistal] += 1\n",
    "\n",
    "        # Inference\n",
    "        activeCells = []\n",
    "\n",
    "        # First, activate cells that have feedforward support\n",
    "        orderedCandidates = sorted((cell for cell in feedforwardSupportedCells),\n",
    "                                   key=lambda x: numActiveSegmentsByCell[x],\n",
    "                                   reverse=True)\n",
    "        for _, cells in itertools.groupby(orderedCandidates,\n",
    "                                          lambda x: numActiveSegmentsByCell[x]):\n",
    "            activeCells.extend(cells)\n",
    "            if len(activeCells) >= self.sdrSize:\n",
    "                break\n",
    "\n",
    "        # If necessary, activate cells that were previously active and have lateral\n",
    "        # support\n",
    "        if len(activeCells) < self.sdrSize and len(activity) >= 2:\n",
    "            prevActiveCells = activity[1][self.layerID][\"activeCells\"]\n",
    "            orderedCandidates = sorted((cell for cell in prevActiveCells\n",
    "                                        if cell not in feedforwardSupportedCells\n",
    "                                        and numActiveSegmentsByCell[cell] > 0),\n",
    "                                       key=lambda x: numActiveSegmentsByCell[x],\n",
    "                                       reverse=True)\n",
    "            for _, cells in itertools.groupby(orderedCandidates,\n",
    "                                              lambda x: numActiveSegmentsByCell[x]):\n",
    "                activeCells.extend(cells)\n",
    "                if len(activeCells) >= self.sdrSize:\n",
    "                    break\n",
    "\n",
    "        # Write the activity\n",
    "        activity[0][self.layerID][\"activeCells\"] = sorted(activeCells)\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Signal that we're now going to observe a different set.\n",
    "\n",
    "        With learning, this signals that we're going to observe a never-before-seen\n",
    "        set.\n",
    "\n",
    "        With inference, this signals to start inferring a new object, ignoring\n",
    "        recent inputs.\n",
    "        \"\"\"\n",
    "        self.isReset = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an array of columns to recognize these objects, then show it Object 1. It will randomly move its sensors to different feature-locations on the object. It will never put two sensors on the same feature-location at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LAYER_4_SIZE = 2048 * 8\n",
    "\n",
    "def createFeatureLocationPool(size=10):\n",
    "    duplicateFound = False\n",
    "    for _ in xrange(5):\n",
    "        candidateFeatureLocations = [frozenset(random.sample(xrange(LAYER_4_SIZE), 40))\n",
    "                                     for featureNumber in xrange(size)]\n",
    "\n",
    "        # Sanity check that they're pretty unique.\n",
    "        duplicateFound = False\n",
    "        for pattern1, pattern2 in itertools.combinations(candidateFeatureLocations, 2):\n",
    "            if len(pattern1 & pattern2) >= 5:\n",
    "                duplicateFound = True\n",
    "                break\n",
    "                \n",
    "        if not duplicateFound:\n",
    "            break\n",
    "        \n",
    "    if duplicateFound:\n",
    "        raise ValueError(\"Failed to generate unique feature-locations\")\n",
    "      \n",
    "    featureLocationPool = {}\n",
    "    for i, featureLocation in enumerate(candidateFeatureLocations):\n",
    "        if i < 26:\n",
    "            name = chr(ord('A') + i)\n",
    "        else:\n",
    "            name = \"Feature-location %d\" % i\n",
    "        featureLocationPool[name] = featureLocation\n",
    "        \n",
    "    return featureLocationPool\n",
    "\n",
    "\n",
    "def experiment(objects, numColumns, selectRandom=True):\n",
    "    #\n",
    "    # Initialize\n",
    "    #\n",
    "    layer2IDs = [\"Column %d Layer 2\" % i for i in xrange(numColumns)]\n",
    "    layer4IDs = [\"Column %d Layer 4\" % i for i in xrange(numColumns)]\n",
    "    layerSizes = dict((layerID, 4096) for layerID in layer2IDs)\n",
    "    layerSizes.update((layerID, LAYER_4_SIZE) for layerID in layer4IDs)\n",
    "    layer2s = dict((l2, SetMemory(layerID=l2,\n",
    "                                  feedforwardID=l4,\n",
    "                                  lateralIDs=layer2IDs,\n",
    "                                  layerSizes=layerSizes,\n",
    "                                  sdrSize=40,\n",
    "                                  minThresholdProximal=20,\n",
    "                                  minThresholdDistal=20))\n",
    "                   for l2, l4 in zip(layer2IDs, layer4IDs))\n",
    "\n",
    "    #\n",
    "    # Learn\n",
    "    #\n",
    "    layer2ObjectSDRs = dict((layerID, {}) for layerID in layer2IDs)\n",
    "    \n",
    "    activity = deque(maxlen=2)\n",
    "    step = dict((layerID, {})\n",
    "                for layerID in itertools.chain(layer2IDs, layer4IDs))\n",
    "\n",
    "    for objectName, objectFeatureLocations in objects.iteritems():\n",
    "        for featureLocationName in objectFeatureLocations:\n",
    "            l4ActiveCells = sorted(featureLocationPool[featureLocationName])\n",
    "            for _ in xrange(2):\n",
    "                activity.appendleft(deepcopy(step))\n",
    "                \n",
    "                # Compute Layer 4\n",
    "                for layerID in layer4IDs:\n",
    "                    activity[0][layerID][\"activeCells\"] = l4ActiveCells\n",
    "                    activity[0][layerID][\"featureLocationName\"] = featureLocationName\n",
    "                    \n",
    "                # Compute Layer 2\n",
    "                for setMemory in layer2s.itervalues():\n",
    "                    setMemory.learningCompute(activity)\n",
    "\n",
    "        for layerID, setMemory in layer2s.iteritems():\n",
    "            layer2ObjectSDRs[layerID][objectName] = activity[0][layerID][\"activeCells\"]\n",
    "            setMemory.reset()\n",
    "            \n",
    "            \n",
    "    #\n",
    "    # Infer\n",
    "    # \n",
    "    objectName = \"Object 1\"\n",
    "    objectFeatureLocations = objects[objectName]\n",
    "    \n",
    "    # Start fresh for inference. No max length because we're also using it as a log.\n",
    "    activity = deque()\n",
    "\n",
    "    success = False\n",
    "    for attempt in xrange(60):\n",
    "        if selectRandom:\n",
    "            featureLocationNames = random.sample(objectFeatureLocations, numColumns)\n",
    "        else:\n",
    "            # Naively move the sensors to touch every point as soon as possible.\n",
    "            start = (attempt * numColumns) % len(objectFeatureLocations)\n",
    "            end = start + numColumns\n",
    "            featureLocationNames = list(objectFeatureLocations)[start:end]\n",
    "            overflow = end - len(objectFeatureLocations)\n",
    "            if overflow > 0:\n",
    "                featureLocationNames += list(objectFeatureLocations)[0:overflow]\n",
    "                \n",
    "        \n",
    "        # Give the feedforward input 3 times so that the lateral inputs have time to spread.\n",
    "        for _ in xrange(3):\n",
    "            activity.appendleft(deepcopy(step))\n",
    "\n",
    "            # Compute Layer 4\n",
    "            for layerID, name in zip(layer4IDs, featureLocationNames):\n",
    "                activity[0][layerID][\"activeCells\"] = sorted(featureLocationPool[name])\n",
    "                activity[0][layerID][\"featureLocationName\"] = name\n",
    "\n",
    "            # Compute Layer 2\n",
    "            for setMemory in layer2s.itervalues():\n",
    "                setMemory.inferenceCompute(activity)\n",
    "        \n",
    "        if all(activity[0][layer2][\"activeCells\"] == layer2ObjectSDRs[layer2][objectName]\n",
    "               for layer2 in layer2IDs):\n",
    "            success = True\n",
    "            print \"Converged after %d touches\" % (attempt + 1)\n",
    "            break\n",
    "\n",
    "    if not success:\n",
    "        print \"Failed to converge after %d touches\" % (attempt + 1)\n",
    "        \n",
    "    return (objectName, activity, layer2ObjectSDRs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize some feature-locations and objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 8 objects, each with 7 feature-locations. Each object is 1 different from each other object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureLocationPool = createFeatureLocationPool(size=8)\n",
    "objects = {\"Object 1\": set([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]),\n",
    "           \"Object 2\": set([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"H\"]),\n",
    "           \"Object 3\": set([\"A\", \"B\", \"C\", \"D\", \"E\", \"G\", \"H\"]),\n",
    "           \"Object 4\": set([\"A\", \"B\", \"C\", \"D\", \"F\", \"G\", \"H\"]),\n",
    "           \"Object 5\": set([\"A\", \"B\", \"C\", \"E\", \"F\", \"G\", \"H\"]),\n",
    "           \"Object 6\": set([\"A\", \"B\", \"D\", \"E\", \"F\", \"G\", \"H\"]),\n",
    "           \"Object 7\": set([\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]),\n",
    "           \"Object 8\": set([\"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're testing L2 in isolation, so these \"A\", \"B\", etc. patterns are L4 representations, i.e. \"feature-locations\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Can one column infer an object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 24 touches\n"
     ]
    }
   ],
   "source": [
    "results = experiment(objects, numColumns=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move sensors deterministically, trying to touch every point with _some_ sensor as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 7 touches\n"
     ]
    }
   ],
   "source": [
    "results = experiment(objects, numColumns=1, selectRandom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Do columns block each other from spreading knowledge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 1 touches\n"
     ]
    }
   ],
   "source": [
    "results = experiment(objects, numColumns=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: How does number of columns affect recognition time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move sensors randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1 columns:\n",
      "Converged after 13 touches\n",
      "\n",
      "With 2 columns:\n",
      "Converged after 10 touches\n",
      "\n",
      "With 3 columns:\n",
      "Converged after 4 touches\n",
      "\n",
      "With 4 columns:\n",
      "Converged after 2 touches\n",
      "\n",
      "With 5 columns:\n",
      "Converged after 2 touches\n",
      "\n",
      "With 6 columns:\n",
      "Converged after 2 touches\n",
      "\n",
      "With 7 columns:\n",
      "Converged after 1 touches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for numColumns in xrange(1, 8):\n",
    "    print \"With %d columns:\" % numColumns\n",
    "    results = experiment(objects, numColumns)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move sensors deterministically, trying to touch every point with _some_ sensor as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1 columns:\n",
      "Converged after 7 touches\n",
      "\n",
      "With 2 columns:\n",
      "Converged after 4 touches\n",
      "\n",
      "With 3 columns:\n",
      "Converged after 3 touches\n",
      "\n",
      "With 4 columns:\n",
      "Converged after 2 touches\n",
      "\n",
      "With 5 columns:\n",
      "Converged after 2 touches\n",
      "\n",
      "With 6 columns:\n",
      "Converged after 2 touches\n",
      "\n",
      "With 7 columns:\n",
      "Converged after 1 touches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for numColumns in xrange(1, 8):\n",
    "    print \"With %d columns:\" % numColumns\n",
    "    results = experiment(objects, numColumns, selectRandom=False)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can I watch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(testObject,\n",
    " activity,\n",
    " layer2ObjectSDRs) = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Column 0: Input: A, Active cells: 271 {'Object 5': 1.0, 'Object 4': 1.0, 'Object 7': 1.0, 'Object 6': 1.0, 'Object 1': 1.0, 'Object 3': 1.0, 'Object 2': 1.0}\n",
      "Column 1: Input: C, Active cells: 271 {'Object 8': 1.0, 'Object 5': 1.0, 'Object 4': 1.0, 'Object 7': 1.0, 'Object 1': 1.0, 'Object 3': 1.0, 'Object 2': 1.0}\n",
      "Column 2: Input: B, Active cells: 272 {'Object 8': 1.0, 'Object 5': 1.0, 'Object 4': 1.0, 'Object 6': 1.0, 'Object 1': 1.0, 'Object 3': 1.0, 'Object 2': 1.0}\n",
      "Column 3: Input: E, Active cells: 272 {'Object 8': 1.0, 'Object 5': 1.0, 'Object 7': 1.0, 'Object 6': 1.0, 'Object 1': 1.0, 'Object 3': 1.0, 'Object 2': 1.0}\n",
      "Column 4: Input: D, Active cells: 273 {'Object 8': 1.0, 'Object 4': 1.0, 'Object 7': 1.0, 'Object 6': 1.0, 'Object 1': 1.0, 'Object 3': 1.0, 'Object 2': 1.0}\n",
      "Column 5: Input: G, Active cells: 272 {'Object 8': 1.0, 'Object 5': 1.0, 'Object 4': 1.0, 'Object 7': 1.0, 'Object 6': 1.0, 'Object 1': 1.0, 'Object 3': 1.0}\n",
      "Column 6: Input: F, Active cells: 266 {'Object 8': 1.0, 'Object 5': 1.0, 'Object 4': 1.0, 'Object 7': 1.0, 'Object 6': 1.0, 'Object 1': 1.0, 'Object 2': 1.0}\n",
      "\n",
      "Step 1\n",
      "Column 0: Input: A, Active cells: 52 {'Object 1': 1.0}\n",
      "Column 1: Input: C, Active cells: 45 {'Object 1': 1.0}\n",
      "Column 2: Input: B, Active cells: 48 {'Object 1': 1.0}\n",
      "Column 3: Input: E, Active cells: 47 {'Object 1': 1.0}\n",
      "Column 4: Input: D, Active cells: 48 {'Object 1': 1.0}\n",
      "Column 5: Input: G, Active cells: 48 {'Object 1': 1.0}\n",
      "Column 6: Input: F, Active cells: 51 {'Object 1': 1.0}\n",
      "\n",
      "Step 2\n",
      "Column 0: Input: A, Active cells: 40 {'Object 1': 1.0}\n",
      "Column 1: Input: C, Active cells: 40 {'Object 1': 1.0}\n",
      "Column 2: Input: B, Active cells: 40 {'Object 1': 1.0}\n",
      "Column 3: Input: E, Active cells: 40 {'Object 1': 1.0}\n",
      "Column 4: Input: D, Active cells: 40 {'Object 1': 1.0}\n",
      "Column 5: Input: G, Active cells: 40 {'Object 1': 1.0}\n",
      "Column 6: Input: F, Active cells: 40 {'Object 1': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t, step in enumerate(reversed(activity)):\n",
    "    print \"Step %d\" % t\n",
    "    \n",
    "    for column in xrange(len(step) / 2):\n",
    "        layer2ID = \"Column %d Layer 2\" % column\n",
    "        layer4ID = \"Column %d Layer 4\" % column\n",
    "        featureLocationName = step[layer4ID][\"featureLocationName\"]\n",
    "        activeCells = set(step[layer2ID][\"activeCells\"])\n",
    "        \n",
    "        layer2Contents = {}\n",
    "        for objectName, objectCells in layer2ObjectSDRs[layer2ID].iteritems():\n",
    "            containsRatio = len(activeCells & set(objectCells)) / float(len(objectCells))\n",
    "            if containsRatio >= 0.20:\n",
    "                layer2Contents[objectName] = containsRatio\n",
    "                \n",
    "        print \"Column %d: Input: %s, Active cells: %d %s\" % (column,\n",
    "                                                             featureLocationName,\n",
    "                                                             len(activeCells),\n",
    "                                                             layer2Contents)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each step is a timestep. We spend 3 timesteps on each touch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagrams\n",
    "\n",
    "Here are some diagrams showing what's going on.\n",
    "\n",
    "## Single column\n",
    "\n",
    "<img src=\"SetMemory_single_column.png\" width=\"600\"/>\n",
    "\n",
    "## Multi column\n",
    "\n",
    "The intercolumn connections are only drawn in one direction.\n",
    "\n",
    "<img src=\"SetMemory_multi_column.png\" width=\"800\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
